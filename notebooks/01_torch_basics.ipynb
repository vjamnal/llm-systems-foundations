{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 · PyTorch Basics\n",
    "\n",
    "This notebook covers the fundamental building blocks of PyTorch:\n",
    "- Tensor creation and properties\n",
    "- Tensor operations (arithmetic, indexing, reshaping)\n",
    "- Broadcasting\n",
    "- Autograd (automatic differentiation)\n",
    "- Moving tensors between CPU and GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "print(f'PyTorch version : {torch.__version__}')\n",
    "print(f'CUDA available  : {torch.cuda.is_available()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Tensor Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Python list\n",
    "a = torch.tensor([1.0, 2.0, 3.0])\n",
    "print('from list       :', a)\n",
    "\n",
    "# Zeros, ones, identity\n",
    "print('zeros(2,3)      :\\n', torch.zeros(2, 3))\n",
    "print('ones(2,3)       :\\n', torch.ones(2, 3))\n",
    "print('eye(3)          :\\n', torch.eye(3))\n",
    "\n",
    "# Random tensors\n",
    "torch.manual_seed(42)\n",
    "print('rand(2,3)       :\\n', torch.rand(2, 3))\n",
    "print('randn(2,3)      :\\n', torch.randn(2, 3))\n",
    "\n",
    "# From NumPy\n",
    "arr = np.array([4.0, 5.0, 6.0])\n",
    "b = torch.from_numpy(arr)\n",
    "print('from numpy      :', b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tensor Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(3, 4)\n",
    "print('shape   :', x.shape)       # torch.Size([3, 4])\n",
    "print('ndim    :', x.ndim)        # 2\n",
    "print('dtype   :', x.dtype)       # torch.float32\n",
    "print('device  :', x.device)      # cpu\n",
    "print('numel   :', x.numel())     # 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Arithmetic & Reduction Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
    "b = torch.tensor([[5.0, 6.0], [7.0, 8.0]])\n",
    "\n",
    "print('a + b  :\\n', a + b)\n",
    "print('a * b  :\\n', a * b)           # element-wise\n",
    "print('a @ b  :\\n', a @ b)           # matrix multiplication\n",
    "print('a.T    :\\n', a.T)             # transpose\n",
    "\n",
    "print('sum    :', a.sum())\n",
    "print('sum(0) :', a.sum(dim=0))      # column sums\n",
    "print('mean   :', a.mean())\n",
    "print('max    :', a.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Indexing & Reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(12, dtype=torch.float32)\n",
    "print('arange  :', x)\n",
    "\n",
    "x2d = x.reshape(3, 4)\n",
    "print('reshape(3,4):\\n', x2d)\n",
    "\n",
    "# Indexing\n",
    "print('row 0   :', x2d[0])\n",
    "print('col 1   :', x2d[:, 1])\n",
    "print('[1,2]   :', x2d[1, 2])\n",
    "\n",
    "# Flatten & unsqueeze\n",
    "print('flatten :', x2d.flatten())\n",
    "print('unsqueeze(0):', x2d.unsqueeze(0).shape)   # (1,3,4)\n",
    "print('squeeze      :', x2d.unsqueeze(0).squeeze(0).shape)  # (3,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch follows NumPy broadcasting rules\n",
    "a = torch.ones(3, 1)   # shape (3,1)\n",
    "b = torch.ones(1, 4)   # shape (1,4)\n",
    "print('(3,1) + (1,4) =', (a + b).shape)   # (3,4)\n",
    "\n",
    "# Practical example: subtract mean per feature\n",
    "data = torch.randn(100, 5)\n",
    "mean = data.mean(dim=0, keepdim=True)   # (1,5)\n",
    "centered = data - mean                  # (100,5) – broadcasting over dim 0\n",
    "print('centered mean ≈ 0:', centered.mean(dim=0).abs().max().item() < 1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Autograd — Automatic Differentiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scalar example: f(x) = 3x² + 2x + 1  →  f'(x) = 6x + 2\n",
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "f = 3 * x**2 + 2 * x + 1\n",
    "f.backward()\n",
    "print(f'f(2)        = {f.item():.1f}')         # 17.0\n",
    "print(f'df/dx at 2  = {x.grad.item():.1f}')   # 14.0  (6*2 + 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector / matrix example\n",
    "w = torch.randn(3, 1, requires_grad=True)\n",
    "X = torch.randn(10, 3)\n",
    "y = torch.randn(10, 1)\n",
    "\n",
    "loss = ((X @ w - y) ** 2).mean()\n",
    "loss.backward()\n",
    "print('w.grad shape:', w.grad.shape)   # (3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.no_grad() — disable gradient tracking (e.g. at inference time)\n",
    "with torch.no_grad():\n",
    "    pred = X @ w\n",
    "print('requires_grad inside no_grad:', pred.requires_grad)  # False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Device Management (CPU ↔ GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "\n",
    "t = torch.randn(3, 3)\n",
    "t_dev = t.to(device)\n",
    "print('tensor device:', t_dev.device)\n",
    "\n",
    "# Move back to CPU for NumPy interop\n",
    "t_cpu = t_dev.cpu()\n",
    "arr = t_cpu.numpy()\n",
    "print('as numpy array shape:', arr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "| Concept | Key function(s) |\n",
    "|---|---|\n",
    "| Create tensors | `torch.tensor`, `torch.zeros`, `torch.randn` |\n",
    "| Shape / type | `.shape`, `.dtype`, `.device` |\n",
    "| Reshape | `.reshape`, `.view`, `.unsqueeze`, `.squeeze` |\n",
    "| Math | `+`, `*`, `@`, `.sum()`, `.mean()` |\n",
    "| Autograd | `requires_grad=True`, `.backward()`, `.grad` |\n",
    "| No grad | `torch.no_grad()` |\n",
    "| Device | `.to(device)`, `.cpu()`, `.cuda()` |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
